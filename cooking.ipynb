{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main-cooking.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3tmMShNFWDjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kaggle Cooking Challenge\n",
        "\n",
        "\n",
        "This is the code for [kaggle cooking challenge](https://). "
      ]
    },
    {
      "metadata": {
        "id": "LKtSiTp2Wo2l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Necesary script for load data from drive"
      ]
    },
    {
      "metadata": {
        "id": "1t9ss5mfV8yx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1fa72565-ab7e-48e3-b498-4f894f0a2dc9"
      },
      "cell_type": "code",
      "source": [
        "# load dataset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdX47oUUWBOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "123cf789-fed1-4622-d49a-1dfe1941ec14"
      },
      "cell_type": "code",
      "source": [
        "# check access to dataset\n",
        "!ls /drive/My\\ Drive/cooking/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svc_output.csv\ttest2.json  train2.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rgupGmMMW8MR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ]
    },
    {
      "metadata": {
        "id": "aDVVD2NjW6e4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkhLPhyeXIgq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ]
    },
    {
      "metadata": {
        "id": "CpZQEgMrXG0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a19ab09f-2450-472f-9d70-048c3b9d20ae"
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/drive/My Drive/cooking/'\n",
        "train = pd.read_json(data_dir + 'train2.json') \n",
        "test = pd.read_json(data_dir + 'test2.json')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "print(50 * '-')\n",
        "\n",
        "print(list(train))\n",
        "print(list(test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39774, 3)\n",
            "(9944, 2)\n",
            "--------------------------------------------------\n",
            "['cuisine', 'id', 'ingredients']\n",
            "['id', 'ingredients']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dXLftipwYEkN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "FBnLquR7XbZl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove outlier\n",
        "train['num_ingredients'] = train['ingredients'].apply(len)\n",
        "train = train[train['num_ingredients'] > 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2NohJz5tYON6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da40da85-5629-45e3-f68b-61b4da64fb3f"
      },
      "cell_type": "code",
      "source": [
        "# remove number\n",
        "# remove word with len smaller than 2\n",
        "# remove hyphen\n",
        "# apply lemmatization\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess(ingredients):\n",
        "    ingredients_text = ' '.join(ingredients)\n",
        "    ingredients_text = ingredients_text.lower()\n",
        "    ingredients_text = ingredients_text.replace('-', ' ')\n",
        "    words = []\n",
        "    for word in ingredients_text.split():\n",
        "        if re.findall('[0-9]', word): continue\n",
        "        if len(word) <= 2: continue\n",
        "        if '’' in word: continue\n",
        "        word = lemmatizer.lemmatize(word)\n",
        "        if len(word) > 0: words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "for ingredient, expected in [\n",
        "    ('Eggs', 'egg'),\n",
        "    ('all-purpose flour', 'all purpose flour'),\n",
        "    ('purée', 'purée'),\n",
        "    ('1% low-fat milk', 'low fat milk'),\n",
        "    ('half & half', 'half half'),\n",
        "    ('safetida (powder)', 'safetida (powder)')\n",
        "]:\n",
        "    actual = preprocess([ingredient])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K-OKe-_EY-EW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train['x'] = train['ingredients'].apply(preprocess)\n",
        "test['x'] = test['ingredients'].apply(preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rGUoQ690ZZIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e1f02c3-94a9-47f4-8f50-4e2f6429e5d5"
      },
      "cell_type": "code",
      "source": [
        "print(list(train))\n",
        "print(list(test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cuisine', 'id', 'ingredients', 'num_ingredients', 'x']\n",
            "['id', 'ingredients', 'x']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OqJ5EJ77aFCu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Features"
      ]
    },
    {
      "metadata": {
        "id": "tQ3FU6MQZsT0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(data):\n",
        "    text_data = [\" \".join(doc) for doc in data.ingredients]\n",
        "    return text_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ovW031m0aCxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_tfidf_vectorize(train, test):\n",
        "    print('start vectorized...')\n",
        "    train_df, test_df = train, test\n",
        "    vect = TfidfVectorizer()\n",
        "\n",
        "    train_features = vect.fit_transform(generate_text(train_df))\n",
        "    test_features = vect.transform(generate_text(test_df))\n",
        "\n",
        "    train_label = [doc for doc in train_df.cuisine]\n",
        "    print('finish vectorized...')\n",
        "\n",
        "    return train_features, train_label, test_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LR-ycTg9aO6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "15fb2db1-3abb-449d-f5de-a86135f49342"
      },
      "cell_type": "code",
      "source": [
        "train_feature, train_label, test_feature = get_tfidf_vectorize(train, test)\n",
        "print(train_feature.shape)\n",
        "print('number of labels:', len(train_label))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start vectorized...\n",
            "finish vectorized...\n",
            "(39768, 2797)\n",
            "number of labels: 39768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nWQUpGAAbLtv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "n7hze8fobOEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_submission(test, file_name, y_pred):\n",
        "    # Submission\n",
        "    print(\"Generate Submission File for \", file_name)\n",
        "    test_id = [doc for doc in test.id]\n",
        "    sub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\n",
        "    sub.to_csv(data_dir + file_name + '_output.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VcB4bvupa4Mg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hyper-tunning"
      ]
    },
    {
      "metadata": {
        "id": "Wj7BCJkoaViM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lb = LabelEncoder()\n",
        "train_label = lb.fit_transform(train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPCUxd6Cwwrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "c7209dc5-f73d-4fdc-df75-8432103a702f"
      },
      "cell_type": "code",
      "source": [
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_feature, train_label, test_size=0.2, random_state=7)\n",
        "\n",
        "tuned_parameters = {'n_estimators':[200,500,750,1000],'max_depth':[20,30,40],'max_features':['sqrt'],'warm_start':[True,False]}\n",
        "\n",
        "scores = ['precision']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=3, scoring='%s_macro' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "o-R4z0u536w7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble models"
      ]
    },
    {
      "metadata": {
        "id": "GZP_4Be-vF4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "7d2637c9-6dd0-4b4b-b197-74b032d3a42b"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_feature, train_label, test_size=0.4, random_state=7)\n",
        "\n",
        "clf0 = OneVsRestClassifier(SVC(C=50, gamma=1.4, coef0=1))\n",
        "clf1 = LinearSVC(loss='squared_hinge', C=0.02, max_iter=1000)\n",
        "clf2 = MultinomialNB(alpha=1)\n",
        "clf3 = SGDClassifier(loss='log')\n",
        "clf4 = RandomForestClassifier(max_features='sqrt') # ~80 #{'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 200}\n",
        "clf5 = GradientBoostingClassifier()\n",
        "\n",
        "eclf3 = VotingClassifier(estimators=[('sgd', clf4)], voting='soft', weights=[1], flatten_transform=True)\n",
        "eclf3.fit(X_train, y_train)\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "#     print('Random forest')\n",
        "#     model3 = RandomForestClassifier()\n",
        "#     model3.fit(train_features, train_label)\n",
        "#     pred3 = model3.predict(test_features)\n",
        "#     pred3 = lb.inverse_transform(pred3)\n",
        "#     DataHelper.save_submission('feature_random_forest', pred3)\n",
        "\n",
        "#     print('GradientBoostingClassifier')\n",
        "#     model4 = GradientBoostingClassifier()\n",
        "#     model4.fit(train_features, train_label)\n",
        "#     pred4 = model4.predict(test_features)\n",
        "#     pred4 = lb.inverse_transform(pred4)\n",
        "#     DataHelper.save_submission('feature_gbc', pred4)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.78      0.36      0.49       188\n",
            "          1       0.77      0.15      0.25       340\n",
            "          2       0.79      0.68      0.73       612\n",
            "          3       0.71      0.89      0.79      1020\n",
            "          4       0.82      0.40      0.54       283\n",
            "          5       0.59      0.57      0.58      1058\n",
            "          6       0.82      0.59      0.69       460\n",
            "          7       0.84      0.92      0.88      1228\n",
            "          8       0.71      0.28      0.40       271\n",
            "          9       0.74      0.92      0.82      3229\n",
            "         10       0.95      0.60      0.74       207\n",
            "         11       0.91      0.62      0.74       556\n",
            "         12       0.81      0.66      0.73       303\n",
            "         13       0.87      0.93      0.90      2582\n",
            "         14       0.88      0.73      0.80       300\n",
            "         15       0.87      0.24      0.38       192\n",
            "         16       0.64      0.82      0.72      1720\n",
            "         17       0.80      0.32      0.46       397\n",
            "         18       0.76      0.76      0.76       643\n",
            "         19       0.82      0.38      0.52       319\n",
            "\n",
            "avg / total       0.77      0.76      0.74     15908\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eC5yKkB_oPTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"SVM 1vsRest\")\n",
        "svc = OneVsRestClassifier(SVC(C=50,\n",
        "                                gamma=1.4,\n",
        "                                coef0=1))\n",
        "\n",
        "svc.fit(train_feature, train_label)\n",
        "print('fit model is finished')\n",
        "svc_prediction = svc.predict(test_feature)\n",
        "svc_prediction = lb.inverse_transform(svc_prediction)\n",
        "save_submission(test, 'svc', svc_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsmZIaEgbq6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('start logistic regression')\n",
        "    logreg = LogisticRegression(C=10, solver='lbfgs', multi_class='multinomial', max_iter=1000, tol=1e-3)\n",
        "    logreg.fit(train_feature, train_label)\n",
        "    log_prediction = logreg.predict(test_feature)\n",
        "    log_prediction = lb.inverse_transform(log_prediction)\n",
        "    DataHelper.save_submission('logregression', log_prediction)\n",
        "\n",
        "    print('start SGD')\n",
        "    sgd = linear_model.SGDClassifier(random_state=0, max_iter=1000, tol=1e-3)\n",
        "    sgd.fit(train_feature, train_label)\n",
        "    sgd_prediction = sgd.predict(test_feature)\n",
        "    sgd_prediction = lb.inverse_transform(sgd_prediction)\n",
        "    DataHelper.save_submission('sgd', sgd_prediction)\n",
        "\n",
        "    print('start Naive bayes')\n",
        "    naive = MultinomialNB()\n",
        "    naive.fit(train_feature, train_label)\n",
        "    naive_prediction = naive.predict(test_feature)\n",
        "    naive_prediction = lb.inverse_transform(naive_prediction)\n",
        "    DataHelper.save_submission('naive_bayes', naive_prediction)\n",
        "\n",
        "    print(\"SVM 1vsRest\")\n",
        "    model = OneVsRestClassifier(SVC(C=100,\n",
        "                                    gamma=1,\n",
        "                                    coef0=1,\n",
        "                                    decision_function_shape=None))\n",
        "\n",
        "    model.fit(train_feature, train_label)\n",
        "    svc_prediction = model.predict(test_feature)\n",
        "    svc_prediction = lb.inverse_transform(svc_prediction)\n",
        "    DataHelper.save_submission('svc', svc_prediction)\n",
        "\n",
        "    print('XGBoost')\n",
        "    xgboost = xgb.XGBClassifier(max_depth=6, n_estimators=1000, learning_rate=0.1\n",
        "                                , min_child_weight=5,\n",
        "                                gamma=1,\n",
        "                                subsample=0.8,\n",
        "                                colsample_bytree=0.8,\n",
        "                                nthread=4,\n",
        "                                scale_pos_weight=1,\n",
        "                                )\n",
        "    xgboost.fit(train_feature, train_label)\n",
        "    xgb_prediction = xgboost.predict(test_feature)\n",
        "    xgb_prediction = lb.inverse_transform(xgb_prediction)\n",
        "    DataHelper.save_submission('xgb', xgb_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}